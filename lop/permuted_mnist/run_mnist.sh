#!/bin/bash
#SBATCH --job-name=mnist      # Job name reflecting ImageNet experiment
#SBATCH --account=jhaddock
#SBATCH --partition=ai
#SBATCH --qos=normal
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=14
#SBATCH --gpus-per-node=1
#SBATCH --time=13-1:00:00
#SBATCH --output=/scratch/gautschi/shin283/loss-of-plasticity/lop/permuted_mnist/log/%j_mnist.out
#SBATCH --error=/scratch/gautschi/shin283/loss-of-plasticity/lop/permuted_mnist/log/%j_mnist.err

# This script is intended to be run as part of a SLURM job array.
# Example submission for 30 experiments (e.g., for 'bp' method after generating configs):
# sbatch --array=0-29 run_mnist.sh

# Ensure you are in the correct directory where temp_cfg/ and expr.py are accessible
# (typically lop/permuted_mnist/)
cd $SLURM_SUBMIT_DIR

# Prerequisites:
# 1. Data must be downloaded and placed in ./data/ as per README.md.
# 2. Temporary configuration files (e.g., temp_cfg/0.json, temp_cfg/1.json, ...)
#    must be generated by running `python3.8 multi_param_expr.py -c cfg/METHOD.json`
#    (e.g., `python3.8 multi_param_expr.py -c cfg/bp.json` for backpropagation)

# Load necessary modules
module load cuda
module load python

# Display GPU information for logging
echo "Date: $(date)"
echo "Host: $(hostname)"
echo "SLURM Job ID: $SLURM_JOB_ID"
nvidia-smi

# Set environment variable for output directory
export OUTPUT_DIR=/scratch/gautschi/shin283/lop

# Activate conda environment
source /scratch/gautschi/shin283/miniconda3/etc/profile.d/conda.sh
conda activate /scratch/gautschi/shin283/conda_envs/lop

# Add diagnostic command to check PyTorch and CUDA setup
echo "--- PyTorch Diagnostics ---"
python3.8 -c "import torch; print(f'PyTorch version: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda}'); print(f'cuDNN version: {torch.backends.cudnn.version()}'); print(f'Number of GPUs: {torch.cuda.device_count()}')"
echo "---------------------------"

# Run the Python script with specified arguments
python3.8 online_expr.py -c temp_cfg_adam_curv/1.json
