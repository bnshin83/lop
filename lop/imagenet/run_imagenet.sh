#!/bin/bash
#SBATCH --job-name=imagenet_expr      # Job name reflecting ImageNet experiment
#SBATCH --account=jhaddock
#SBATCH --partition=ai
#SBATCH --qos=normal
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=14
#SBATCH --gpus-per-node=1
#SBATCH --time=10:00:00
#SBATCH --output=/scratch/gautschi/shin283/loss-of-plasticity/lop/imagenet/log/%j_imagenet.out
#SBATCH --error=/scratch/gautschi/shin283/loss-of-plasticity/lop/imagenet/log/%j_imagenet.err

# This script is intended to be run as part of a SLURM job array.
# Example submission for 30 experiments (e.g., for 'bp' method after generating configs):
# sbatch --array=0-29 run_imagenet.sh

# Ensure you are in the correct directory where temp_cfg/ and expr.py are accessible
# (typically lop/imagenet/)
cd $SLURM_SUBMIT_DIR

# Prerequisites:
# 1. Data must be downloaded and placed in ./data/ as per README.md.
# 2. Temporary configuration files (e.g., temp_cfg/0.json, temp_cfg/1.json, ...)
#    must be generated by running `python3.8 multi_param_expr.py -c cfg/METHOD.json`
#    (e.g., `python3.8 multi_param_expr.py -c cfg/bp.json` for backpropagation)

# Load necessary modules
module load cuda
module load python

# Display GPU information for logging
echo "Date: $(date)"
echo "Host: $(hostname)"
echo "SLURM Job ID: $SLURM_JOB_ID"
nvidia-smi

# Set environment variable for output directory
export OUTPUT_DIR=/scratch/gautschi/shin283/lop

# Activate conda environment
source /scratch/gautschi/shin283/miniconda3/etc/profile.d/conda.sh
conda activate /scratch/gautschi/shin283/conda_envs/lop

# Run the Python script with specified arguments
# python3.8 multi_param_expr.py -c cfg/bp.json  # Already ran this to generate config files
python3.8 single_expr_curv.py -c temp_cfg_bp/0.json
