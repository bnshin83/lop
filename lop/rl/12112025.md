# Discussion Notes: Margin Analysis Timing for Stationary RL
**Date: December 11, 2025**

---

## The Open Question: Margin Timing for Ant (Stationary)

For Ant without explicit task changes, what is the correct approach for margin analysis?

### Current Implementation

**Dormant Units:**
- Discrete 1000-step windows
- Reset after each window (`short_term_feature_activity *= 0`)
- Computed at steps 1000, 2000, 3000, ...

**Margin Analysis:**
- Rolling 1000-observation buffer (never reset)
- Computed every PPO update (every `bs` steps, e.g., 2048)
- Buffer contains most recent 1000 observations

### The Inconsistency

```
Step:    0    1000   2000   2048   3000   4000   4096
         |     |      |      |      |      |      |
Dormant: |  CALC   CALC    |   CALC   CALC    |
         | [0-999][1000-1999]  [2000-2999][3000-3999]
         |                 |                  |
Margin:  |                CALC              CALC
         |            [1048-2047]        [3096-4095]
```

**Problems:**
1. Different logging intervals (1000 vs 2048 steps)
2. Different window types (discrete vs rolling)
3. Can't directly compare dormant% vs dead% on same chart

---

## Options for Ant Case

**Option A: Current (Rolling buffer, PPO-aligned)**
```
Every PPO update (2048 steps):
  - Buffer contains steps [N-999, N]
  - Compute margins with current weights
  - Answers: "Current network on recent data"
```

**Option B: Discrete windows (Dormant-aligned)**
```
Every 1000 steps:
  - Window N contains steps [N*1000, (N+1)*1000-1]
  - Compute BOTH dormant AND margins on same window
  - Answers: "Directly comparable metrics"
```

**Option C: Predictive approach**
```
At step 2000:
  - Use observations from window 0 (steps 0-999)
  - Predict which neurons will be dead in window 1 (steps 1000-1999)
  - Verify prediction against actual activity
```

---

## Key Question

For the Ant case where the task doesn't change:

Should margins be computed using:
- **Same window as dormant** (Option B) for direct comparison?
- **Rolling buffer** (Option A) for continuous tracking?
- **Previous window to predict next** (Option C) for validation?

---

## Reference

See `12102025.md` Section 8 for detailed discussion on margin analysis in stationary RL.

---

## Final Plan: Predictive Margins in Ant with "Window = One PPO Update"

### Assumptions

- **PPO update length** \(= \text{bs} = 2048\) steps.
- Define **window \(k\)** as the 2048 environment steps used for PPO update \(k\).

So:

- **Window 0**: steps \([0, 2047]\)
- **Window 1**: steps \([2048, 4095]\)
- **Window 2**: steps \([4096, 6143]\)
- …

Let \(\theta_k\) = network parameters **after finishing update \(k\)** (i.e., after training on window \(k\)).

---

### Step-by-Step Protocol

For each PPO update \(k\) (starting from \(k = 0\)):

1. **Collect data for window \(k\)**
   - Run the current policy for 2048 steps, store states \(M_k = \{x_t : t \in [k\cdot \text{bs}, (k+1)\cdot \text{bs}-1]\}\).

2. **Train PPO on window \(k\)**
   - Use \(M_k\) to run PPO update \(k\).
   - After training, you have updated params \(\theta_k\).

3. **Collect the *next* window's data under \(\theta_k\)**
   - Roll out another 2048 steps with policy \(\pi_{\theta_k}\).
   - Call that data \(M_{k+1} = \{x_t : t \in [(k+1)\cdot \text{bs}, (k+2)\cdot \text{bs}-1]\}\).

4. **Compute predictive margins at the boundary between windows**
   - **Freeze** \(\theta_k\). Do *not* use \(\theta_{k+1}\) yet.
   - For each layer \(l\), each neuron \(j\):

     \[
     \text{margin}_{j}^{(k \to k+1)} \;=\; \max_{x \in M_{k+1}} \big(w_{j,l}(\theta_k)^\top x_l + b_{j,l}(\theta_k)\big)
     \]

     where \(x_l\) is the activation going into layer \(l\) when you run \(x\) through the network with params \(\theta_k\).

   - Interpretation:
     - **margin\(_j^{(k\to k+1)} < 0\)**: with the params learned on window \(k\), neuron \(j\) would be **dead on all states in the next window** \(M_{k+1}\).
     - **margin\(_j^{(k\to k+1)} \approx 0\)**: neuron is **at risk** of becoming dead on the upcoming data.
     - **margin\(_j^{(k\to k+1)} > 0\)**: neuron is **alive** on at least some of the next 2048 steps.

5. **Then train on window \(k+1\)**
   - Now run PPO update \(k+1\) using \(M_{k+1}\), producing \(\theta_{k+1}\).
   - After this, you can check **which neurons are actually dead on \(M_{k+1}\) under \(\theta_{k+1}\)** (using the same max-margin rule with \(\theta_{k+1}\) and \(M_{k+1}\)).

---

### What This Measures in Stationary Ant

- At each update boundary \(k\), you get a **predictive margin** for each neuron: how close it is to being dead **on the *next* 2048 steps**, given the weights you have *now*.
- You can then compare:
  - **Predictive margin at \(k\)** vs **actual dead/alive status after training on window \(k+1\)**.
- Even though Ant is stationary, the policy keeps changing, so \(M_k\) and \(M_{k+1}\) are slightly different distributions. This protocol tells you:
  - **Do low predictive margins at the end of window \(k\) actually forecast neuron death in window \(k+1\)?**
  - How early before death do margins start to go negative or near-zero?

---

## Implementation Details

The predictive margin analysis is implemented in `run_ppo_wandb.py` with the following metrics logged to WandB:

### Logged Metrics

1. **`predictive_margin/*`** - Margins computed with \(\theta_{k-1}\) on \(M_k\)
   - Uses weights from the PREVIOUS update on the CURRENT window's data
   - Answers: "Would neurons that were alive before training still be alive on this new data?"

2. **`actual_margin/*`** - Margins computed with \(\theta_k\) on \(M_k\)
   - Uses current weights on current window's data
   - Answers: "Which neurons are dead/at-risk after training on this window?"

3. **`predictive/*`** - Comparison metrics
   - `predicted_dead` vs `actual_dead`: Did low predictive margins forecast actual death?
   - Per-layer breakdown for detailed analysis

### Key Implementation Notes

- Window size = PPO batch size (bs = 2048 steps)
- Weights are saved after each PPO update using `copy.deepcopy()`
- Predictive margins start from update k=2 (need previous weights)
- Both predictive and actual margins are computed and stored for offline analysis

### Logging Intervals (Aligned for Consistency)

| Metric | Interval | Notes |
|--------|----------|-------|
| Dormant units | 1024 steps | Half of PPO batch size |
| Weight magnitudes | 1024 steps | Same as dormant |
| Stable rank | 10240 steps | 10× dormant interval |
| Margin analysis | Every PPO update | 2048 steps |

### Running Experiments

**Ant (stationary):**
```bash
sbatch run_ant.sh  # Uses cfg/ant/std.yml
```

**SlipperyAnt (non-stationary):**
```bash
sbatch run_sant.sh  # Uses cfg/sant/std.yml
```

Both experiments use the same `run_ppo_wandb.py` with predictive margin analysis enabled.
